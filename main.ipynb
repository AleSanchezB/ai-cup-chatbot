{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be722850-349a-468d-ad54-362d5219890f",
   "metadata": {},
   "source": [
    "# Libreta AI Cup 2025\n",
    "Esta libreta está siendo desarrolada por:\n",
    "1. p\n",
    "2. p\n",
    "3. \n",
    "\n",
    "Y su asesor:\n",
    "1. Braulio Sánchez\n",
    "\n",
    "Aquí describan el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8048afd7-e83f-49e4-ac86-ff344c1ee463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10fa64e-d56e-42a1-9bfa-5433d5518d6b",
   "metadata": {},
   "source": [
    "- Obtener todas las imagenes dado un folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3408ddff-f642-477e-bf39-3ec9dccbc8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images(path):\n",
    "    return glob.glob(os.path.join(path, \"*.jpg\")) + \\\n",
    "           glob.glob(os.path.join(path, \"*.png\")) + \\\n",
    "           glob.glob(os.path.join(path, \"*.jpeg\")) + \\\n",
    "           glob.glob(os.path.join(path, \"*.bmp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c06f4b-1ea5-4662-b144-85cfe5e113ce",
   "metadata": {},
   "source": [
    "# **Clases del modelo**\n",
    "### ***TripletNet***:\n",
    "    - Se usa un modelo pre-entrenado para asi poder realizar un entrenamiento mucho más óptimo\n",
    "### ***TripletLoss***:\n",
    "    - Se usa para poder obtener la pérdida tomando en cuenta la siguiente función: \n",
    "$$Loss=max(d(A,P)−d(A,N)+margin,0)$$\n",
    "\n",
    "### ***TripletDataset***:\n",
    "    - Esta clase es donde guardaremos nuestro dataset, además se implementan funciones para poder obtener su tamaño, y poder obtener las 3 imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8a91c56a-69bf-4561-a2e4-1c76be86b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base (ResNet18) con capa de embeddings\n",
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.base_model = models.resnet18(pretrained=pretrained)\n",
    "        self.base_model.fc = nn.Linear(512, 128)  # Reducimos a 128 dimensiones\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f8050-2e55-4b3b-b34a-b923dc608d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        # Calculamos las distancias entre los embeddings\n",
    "        positive_distance = F.pairwise_distance(anchor, positive, p=2)\n",
    "        negative_distance = F.pairwise_distance(anchor, negative, p=2)\n",
    "        \n",
    "        # Triplet loss\n",
    "        loss = torch.clamp(positive_distance - negative_distance + self.margin, min=0.0)\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d8a33-3b20-4913-a59d-56f0a199ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, folder_defective, folder_non_defective, transform=None):\n",
    "        self.folder_defective = folder_defective\n",
    "        self.folder_non_defective = folder_non_defective\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Obtener las imágenes de cada clase\n",
    "        self.defective_images = get_all_images(folder_defective)\n",
    "        \n",
    "        self.non_defective_images = get_all_images(folder_non_defective)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.defective_images) + len(self.non_defective_images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Obtener las imágenes de cada clase\n",
    "        anchor_img = Image.open(self.defective_images[idx % len(self.defective_images)]).convert(\"RGB\")\n",
    "        positive_img = Image.open(self.defective_images[(idx + 1) % len(self.defective_images)]).convert(\"RGB\")\n",
    "        negative_img = Image.open(self.non_defective_images[idx % len(self.non_defective_images)]).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            anchor_img = self.transform(anchor_img)\n",
    "            positive_img = self.transform(positive_img)\n",
    "            negative_img = self.transform(negative_img)\n",
    "        \n",
    "        return anchor_img, positive_img, negative_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb2422b-5c91-452e-a43a-72c91477df92",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "- Se utiliza para realizar el data augmentation. Donde se puede modificar las transformaciones para poder hacer mejores imagenes con mejor calidad y asi obtener unos mejores resultados al entrenar al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e3b51-5b7e-49f6-bbc3-0fd1de76e0ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_augmentations():\n",
    "    \"\"\"\n",
    "    Devuelve una secuencia de transformaciones para hacer Data Augmentation.\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        transforms.RandomAffine(30, shear=10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def augment_and_save_image(image_path, output_folder, image_name):\n",
    "    \"\"\"\n",
    "    Aplica data augmentation a una imagen y guarda las imágenes augmentadas en una carpeta.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Cargar la imagen\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Obtener las transformaciones\n",
    "    augmentation = get_augmentations()\n",
    "\n",
    "    # Crear varias imágenes aumentadas y guardarlas\n",
    "    for i in range(5):  # Generar 5 versiones aumentadas de cada imagen\n",
    "        augmented_image = augmentation(image)\n",
    "        \n",
    "        # Convertir el tensor de nuevo a imagen\n",
    "        augmented_image = transforms.ToPILImage()(augmented_image)\n",
    "        \n",
    "        # Guardar la imagen en el folder de salida\n",
    "        augmented_image.save(os.path.join(output_folder, f\"{image_name}_aug_{i}.jpg\"))\n",
    "\n",
    "def augment_dataset(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Aplica data augmentation a todas las imágenes de un directorio y las guarda en el directorio de salida.\n",
    "    \"\"\"\n",
    "    image_paths = get_all_images(input_folder)  # Obtener todas las imágenes del folder\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        image_name = os.path.splitext(os.path.basename(image_path))[0]  # Obtener nombre base de la imagen\n",
    "        augment_and_save_image(image_path, output_folder, image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c4f0d-dec6-4c75-a4c9-d6f966a50816",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "input_folder = \"dataset/Defective\"  # Ruta a las imágenes originales\n",
    "output_folder = \"dataset_augmented/Defective\"\n",
    "augment_dataset(input_folder, output_folder)\n",
    "\n",
    "input_folder = \"dataset/Non-defective\"  # Ruta a las imágenes originales\n",
    "output_folder = \"dataset_augmented/Non-Defective\"\n",
    "augment_dataset(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a9428-b836-4ca9-ab00-79709fd66eef",
   "metadata": {},
   "source": [
    "# Configuracón e inicialización del modelo\n",
    "- Si contamos con gráfica nvidia se usará para entrenar al modelo, de lo contrario usará tu cpu.\n",
    "- Se inicializa el modelo **Triplet Loss**\n",
    "- Además se agregan unas optimizaciones (Ojo: Esto se puede modificar para poder obtener un mejor resultado de entramiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b60bffc-4607-4113-a1c3-5ce0c497d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Inicializar el modelo\n",
    "model = TripletNet().to(device)\n",
    "\n",
    "# Inicializar Triplet Loss\n",
    "triplet_loss = TripletLoss(margin=1.0).to(device)\n",
    "\n",
    "# Optimizer\n",
    "criterion = nn.TripletMarginLoss(margin=1.0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1ce75a-67bf-4564-9b2b-4a4487be2f52",
   "metadata": {},
   "source": [
    "# Transfomarciones y carga de los datos\n",
    "- Obtenemos todas las imgenes desde nuestro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fdd2bd-004b-4690-9924-02605ce17a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones para las imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "defective_dir = \"dataset_augmented/Defective/\"\n",
    "non_defective_dir = \"dataset_augmented/Non-Defective/\"\n",
    "\n",
    "# Cargar los datos\n",
    "train_dataset = TripletDataset(defective_dir, non_defective_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939a12d-3741-4294-85c1-0c7f30995b49",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo\n",
    "- Aquí hay que tener cuidado al momento de entrenar un modelo, ya que puede llegar a ser muy pesado dependiendo de que modelo estemos entrenando y de nuestro dataset. Por ende debemos tener cuidado con las epocas que realizamos. Al final se muestra la grafica de la perdida (La cual se puede observar extraña debido a que nuestro dataset no es el mejor por lo que puede haber cambios en la péridida y mal resultado de entrenamiento, entre mas cerca a 0 mejor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a9404-72f9-44a2-8196-ee3a10070229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Para almacenar los valores de la pérdida en cada época\n",
    "losses = []\n",
    "\n",
    "# Entrenamiento modificado para almacenar las pérdidas\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (anchor, positive, negative) in enumerate(train_loader):\n",
    "        anchor = anchor.to(device)\n",
    "        positive = positive.to(device)\n",
    "        negative = negative.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        anchor_output = model(anchor)\n",
    "        positive_output = model(positive)\n",
    "        negative_output = model(negative)\n",
    "\n",
    "        loss = triplet_loss(anchor_output, positive_output, negative_output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Graficar la pérdida\n",
    "plt.plot(range(1, num_epochs + 1), losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss During Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b92e001-4d4f-4340-a595-519706456ce2",
   "metadata": {},
   "source": [
    "# Segunda forma de entrenamiento\n",
    "- Al igual que en la celda anterior, aqui se hace una optimizacón diferente, pueden ir probrando con ambas y viendo caul es la mejor. Investiguen como funcionan y cual les conviene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04019746-8316-4e2a-9bc4-636db0839092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar un scheduler para el optimizador\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# En cada época, actualizar el scheduler\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (anchor, positive, negative) in enumerate(train_loader):\n",
    "        anchor = anchor.to(device)\n",
    "        positive = positive.to(device)\n",
    "        negative = negative.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        anchor_output = model(anchor)\n",
    "        positive_output = model(positive)\n",
    "        negative_output = model(negative)\n",
    "\n",
    "        loss = triplet_loss(anchor_output, positive_output, negative_output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Actualizar el scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fadced1-0e5d-48dc-9d90-549ff097d0a8",
   "metadata": {},
   "source": [
    "# Guardar el modelo entrenado\n",
    "- Vamos a guardar el modelo para no tener que estar entrenandolo cada vez que iniciamos nuestra libreta. Por lo cual podemos usarlo en otros programas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15931f13-9b89-417f-b0dd-258168e4325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "torch.save(model.state_dict(), \"model/triplet_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864cfc1b-e213-4f4c-8148-ca4d211482f2",
   "metadata": {},
   "source": [
    "# Pruebas y Observaciones\n",
    "- Aqui se hacen las pruebas de nuestro modelo con nuestras imagenes de testeo. Mucho cuidado, no usar imagenes de testeo para entrenar y viceversa. Ya que eso perjudica nuestro entrenamieto, a este tipo de entrenamiento se le llama Aprendizaje Supervisado ya que nosotros tenemos nuestro train dataset y nuestro test dataset.\n",
    "- Para poder ver que tipo es una imagen es en base al promedio (no es la unica forma, si encuentran una mejor forma para decir que una imagen es de un tipo pueden probrala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "02e050af-d2e1-4073-8a0a-0361995dc6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los embeddings promedio para las imágenes defectuosas y no defectuosas\n",
    "def get_average_embedding(image_paths):\n",
    "    embeddings = []\n",
    "    for image_path in image_paths:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        img = transform(img).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embedding = model(img)\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    # Calcular el promedio de los embeddings\n",
    "    return torch.mean(torch.stack(embeddings), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e4a3ef0d-aa7d-47c1-a7eb-5b02bc71a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener el embedding de una imagen\n",
    "def get_embedding(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embedding = model(img)\n",
    "    return embedding\n",
    "\n",
    "# Función para clasificar una imagen nueva\n",
    "def classify_image(image_path):\n",
    "    test_embedding = get_embedding(image_path)\n",
    "    # Obtener imágenes de cada clase\n",
    "    defective_images = get_all_images(\"dataset/Defective\")\n",
    "    non_defective_images = get_all_images(\"dataset/Non-defective\")\n",
    "    \n",
    "    defective_avg = get_average_embedding(defective_images)\n",
    "    non_defective_avg = get_average_embedding(non_defective_images)\n",
    "\n",
    "    dist_defective = F.pairwise_distance(test_embedding, defective_avg).item()\n",
    "    dist_non_defective = F.pairwise_distance(test_embedding, non_defective_avg).item()\n",
    "\n",
    "    # print(f\"Distancia a Defective: {dist_defective:.4f}\")\n",
    "    # print(f\"Distancia a Non-Defective: {dist_non_defective:.4f}\")\n",
    "\n",
    "    if dist_defective < dist_non_defective:\n",
    "        return \"Defective\"\n",
    "    else:\n",
    "        return \"Non-Defective\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8fa57de9-9530-4fdc-932e-8279910ad9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen es clasificada como: Non-Defective\n",
      "La imagen es clasificada como: Non-Defective\n",
      "Se clasificaron como defective: 0 de 2\n",
      "Se clasificaron como non-defective: 2 de 2\n"
     ]
    }
   ],
   "source": [
    "defective = 0\n",
    "non_defective = 0\n",
    "\n",
    "test_imgs = get_all_images(\"test\")\n",
    "\n",
    "for img in test_imgs:\n",
    "    result = classify_image(img)\n",
    "    if result == \"Defective\":\n",
    "        defective += 1\n",
    "    else:\n",
    "        non_defective += 1\n",
    "    print(f\"La imagen es clasificada como: {result}\")\n",
    "print(f\"Se clasificaron como defective: {defective} de {len(test_imgs)}\")\n",
    "print(f\"Se clasificaron como non-defective: {non_defective} de {len(test_imgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11568bbc-29c3-4f3b-b90e-56452ee4dbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
